{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea3b6a",
   "metadata": {},
   "source": [
    "### Talking points\n",
    "\n",
    "- jump from previous stuff (not related to what we've learned so far)\n",
    "- just soemthing cool\n",
    "- think of it as \"what else can we do with text and deep learning\"\n",
    "\n",
    "# RAG\n",
    "\n",
    "- embeddings documents\n",
    "- vector search\n",
    "- contextual summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff81ba28",
   "metadata": {},
   "source": [
    "## Step 1: Pulling a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d99e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "ds = load_dataset(\"SetFit/20_newsgroups\")\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140cd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c344a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Subsample targets which start with talk.politics\n",
    "# df_train = df_train[df_train['label_text'].str.startswith('talk.politics')] # optional; sentence tf is very fast\n",
    "# df_query = df_query[df_query['label_text'].str.startswith('talk.politics')] # optional; sentence tf is very fast\n",
    "\n",
    "# df_train.shape, df_query.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cbabaf",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "Lets use a transformer model to create embedding representing the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19965ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embedding model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b56ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5a8bc5c",
   "metadata": {},
   "source": [
    "# Vector Store\n",
    "\n",
    "(not necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24ab85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b04ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff0e20e1",
   "metadata": {},
   "source": [
    "# Lets try it out on some document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 100\n",
    "doc = df_query.iloc[i]\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeb5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530028f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find the relevant indices using faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59ca4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0a6080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c0660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seems good?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95916dd6",
   "metadata": {},
   "source": [
    "# Paraphrasing responses together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8911b",
   "metadata": {},
   "source": [
    "### How to use a local LLM?\n",
    "\n",
    "We will use a lightweight qwen model -- https://ollama.com/library/qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4bb5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat, generate\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='qwen:0.5b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a2b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(model='qwen:0.5b', prompt=\"Why is the sky blue?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3462ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a prompt\n",
    "\n",
    "context = \"\\n\\n\".join(similar_articles)\n",
    "prompt = f\"\"\"You are a helpful assistant. For a given user question, summarize or paraphrase the key points that are relevant to this question.\n",
    "Note that the context is not a direct response to answer user question. Rather, we want to provide the user with a summary of what other people are asking on the topic. \n",
    "Your summary should not be too short. At least 4-8 sentences. In english.\n",
    "\n",
    "User Question: \n",
    "--------------\n",
    "```\n",
    "{doc.text}\n",
    "```\n",
    "\n",
    "Context:\n",
    "--------\n",
    "{context}\n",
    "\n",
    "Summary:\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ffef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate(model='qwen:0.5b', prompt=prompt).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975401fc",
   "metadata": {},
   "source": [
    "## Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de2425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", \"facebook/bart-large-cnn\")\n",
    "\n",
    "# Summarize each article\n",
    "for i, article in enumerate(similar_articles, 1):\n",
    "    summary = summarizer(article, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
    "    print(f\"\\n--- Summary of Article {i} ---\\n\")\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f183cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Not exactly the same (dont expect this model to do what qwen can do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13610da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98065e83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
